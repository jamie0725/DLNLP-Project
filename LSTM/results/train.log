=============== HYPERPARAMETER SETTING ===============
mode : train
lr : 0.001
epochs : 10
batch_size : 64
num_hidden : 256
max_norm : 5.0
lstm_layer : 2
lstm_bidirectional : True
embed_trainable : False
=============== DATA PROCESSING ===============
Statistics of Label Mapping:
* Class: {0: 'ABBREVIATION', 1: 'ENTITY', 2: 'DESCRIPTION', 3: 'HUMAN', 4: 'LOCATION', 5: 'NUMERIC'}
+ Total: 6
Statistics of Training Set:
* Number of data in class ABB: 180
* Number of data in class ENT: 1800
* Number of data in class DES: 1800
* Number of data in class HUM: 1800
* Number of data in class LOC: 1800
* Number of data in class NUM: 1800
+ Total: 9180
Statistics of Validation Set:
* Number of data in class ABB: 20
* Number of data in class ENT: 200
* Number of data in class DES: 200
* Number of data in class HUM: 200
* Number of data in class LOC: 200
* Number of data in class NUM: 200
+ Total: 1020
Statistics of Test Set:
* Number of data in class ABB: 9
* Number of data in class ENT: 94
* Number of data in class DES: 138
* Number of data in class HUM: 65
* Number of data in class LOC: 81
* Number of data in class NUM: 113
+ Total: 500
=============== LOAD EMBEDDINGS ===============
embeddings_shape:(4164, 300)
vocab_size:4164
=============== MODEL TRAINING ===============
iter=10, loss=1.658237, acc=0.2969
iter=20, loss=1.696049, acc=0.2031
iter=30, loss=1.612770, acc=0.1875
iter=40, loss=1.730131, acc=0.1562
iter=50, loss=1.665377, acc=0.2500
iter=60, loss=1.640211, acc=0.2812
iter=70, loss=1.674419, acc=0.2500
iter=80, loss=1.607556, acc=0.4062
iter=90, loss=1.638965, acc=0.2344
iter=100, loss=1.538077, acc=0.2188
iter=110, loss=1.630833, acc=0.2656
iter=120, loss=1.249751, acc=0.4219
iter=130, loss=1.388760, acc=0.2969
iter=140, loss=1.417942, acc=0.3750
iter=150, loss=1.395483, acc=0.4375
iter=160, loss=1.222154, acc=0.5000
iter=170, loss=1.349235, acc=0.3906
iter=180, loss=1.172512, acc=0.5781
iter=190, loss=1.198836, acc=0.5781
iter=200, loss=1.257815, acc=0.5469
iter=210, loss=1.070133, acc=0.5938
iter=220, loss=1.177045, acc=0.5625
iter=230, loss=1.074505, acc=0.6094
iter=240, loss=0.777347, acc=0.7031
iter=250, loss=0.971682, acc=0.6719
iter=260, loss=0.948813, acc=0.7500
iter=270, loss=0.642620, acc=0.7500
iter=280, loss=0.602314, acc=0.7656
iter=290, loss=0.571008, acc=0.8125
iter=300, loss=0.865550, acc=0.7500
iter=310, loss=0.660165, acc=0.7812
iter=320, loss=0.534645, acc=0.8281
iter=330, loss=0.566461, acc=0.7812
iter=340, loss=0.446031, acc=0.8594
iter=350, loss=0.372183, acc=0.8906
iter=360, loss=0.602206, acc=0.7812
iter=370, loss=0.458058, acc=0.8281
iter=380, loss=0.399581, acc=0.8594
iter=390, loss=0.438652, acc=0.8906
iter=400, loss=0.293128, acc=0.9062
iter=410, loss=0.578136, acc=0.8594
iter=420, loss=0.394494, acc=0.8594
iter=430, loss=0.321914, acc=0.8750
iter=440, loss=0.210077, acc=0.9375
iter=450, loss=0.227373, acc=0.9375
iter=460, loss=0.247619, acc=0.9375
iter=470, loss=0.280566, acc=0.9219
iter=480, loss=0.311156, acc=0.9375
iter=490, loss=0.247133, acc=0.9375
iter=500, loss=0.215055, acc=0.9531
iter=510, loss=0.272295, acc=0.9375
iter=520, loss=0.131599, acc=0.9531
iter=530, loss=0.073476, acc=0.9688
iter=540, loss=0.217263, acc=0.9375
iter=550, loss=0.195801, acc=0.9375
iter=560, loss=0.215373, acc=0.9375
iter=570, loss=0.185279, acc=0.9219
iter=580, loss=0.485675, acc=0.8906
iter=590, loss=0.086747, acc=0.9844
iter=600, loss=0.268622, acc=0.8906
iter=610, loss=0.206000, acc=0.9375
iter=620, loss=0.138974, acc=0.9688
iter=630, loss=0.144078, acc=0.9688
iter=640, loss=0.508213, acc=0.8750
iter=650, loss=0.312604, acc=0.9062
iter=660, loss=0.147073, acc=0.9531
iter=670, loss=0.156964, acc=0.9688
iter=680, loss=0.202390, acc=0.9375
iter=690, loss=0.107313, acc=0.9844
iter=700, loss=0.046001, acc=1.0000
iter=710, loss=0.142877, acc=0.9531
iter=720, loss=0.097917, acc=0.9643
iter=730, loss=0.027309, acc=1.0000
iter=740, loss=0.226935, acc=0.9531
iter=750, loss=0.255403, acc=0.9375
iter=760, loss=0.308740, acc=0.9062
iter=770, loss=0.058248, acc=0.9844
iter=780, loss=0.330613, acc=0.9219
iter=790, loss=0.071510, acc=0.9688
iter=800, loss=0.209150, acc=0.9375
iter=810, loss=0.017678, acc=1.0000
iter=820, loss=0.075617, acc=0.9688
iter=830, loss=0.246680, acc=0.9062
iter=840, loss=0.213330, acc=0.9531
iter=850, loss=0.086396, acc=0.9688
iter=860, loss=0.077020, acc=0.9844
iter=870, loss=0.071734, acc=0.9688
iter=880, loss=0.024739, acc=0.9844
iter=890, loss=0.125235, acc=0.9688
iter=900, loss=0.202712, acc=0.9531
iter=910, loss=0.030857, acc=1.0000
iter=920, loss=0.208680, acc=0.9219
iter=930, loss=0.030668, acc=0.9844
iter=940, loss=0.118948, acc=0.9688
iter=950, loss=0.021513, acc=1.0000
iter=960, loss=0.046914, acc=0.9844
iter=970, loss=0.004962, acc=1.0000
iter=980, loss=0.121071, acc=0.9688
iter=990, loss=0.114186, acc=0.9531
iter=1000, loss=0.068616, acc=0.9844
iter=1010, loss=0.157520, acc=0.9688
iter=1020, loss=0.012262, acc=1.0000
iter=1030, loss=0.075124, acc=0.9688
iter=1040, loss=0.036392, acc=1.0000
iter=1050, loss=0.119212, acc=0.9688
iter=1060, loss=0.054100, acc=0.9688
iter=1070, loss=0.037235, acc=0.9844
iter=1080, loss=0.218325, acc=0.9688
iter=1090, loss=0.204338, acc=0.9531
iter=1100, loss=0.038124, acc=0.9844
iter=1110, loss=0.026655, acc=1.0000
iter=1120, loss=0.022685, acc=0.9844
iter=1130, loss=0.064478, acc=0.9844
iter=1140, loss=0.137777, acc=0.9531
iter=1150, loss=0.022906, acc=1.0000
iter=1160, loss=0.100719, acc=0.9688
iter=1170, loss=0.031774, acc=0.9844
iter=1180, loss=0.167442, acc=0.9531
iter=1190, loss=0.061886, acc=0.9844
iter=1200, loss=0.021794, acc=1.0000
iter=1210, loss=0.012820, acc=1.0000
iter=1220, loss=0.088707, acc=0.9688
iter=1230, loss=0.113499, acc=0.9531
iter=1240, loss=0.064072, acc=0.9844
iter=1250, loss=0.009993, acc=1.0000
iter=1260, loss=0.029543, acc=1.0000
iter=1270, loss=0.073632, acc=0.9844
iter=1280, loss=0.011827, acc=1.0000
iter=1290, loss=0.106438, acc=0.9688
iter=1300, loss=0.094626, acc=0.9688
iter=1310, loss=0.015183, acc=1.0000
iter=1320, loss=0.033514, acc=0.9844
iter=1330, loss=0.081885, acc=0.9844
iter=1340, loss=0.010895, acc=1.0000
iter=1350, loss=0.107483, acc=0.9688
iter=1360, loss=0.096574, acc=0.9844
iter=1370, loss=0.226149, acc=0.9531
iter=1380, loss=0.057029, acc=0.9844
iter=1390, loss=0.047167, acc=0.9844
iter=1400, loss=0.229388, acc=0.9531
iter=1410, loss=0.155990, acc=0.9844
iter=1420, loss=0.179140, acc=0.9531
iter=1430, loss=0.124436, acc=0.9688
iter=1440, loss=0.211627, acc=0.9643
