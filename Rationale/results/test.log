=============== HYPERPARAMETER SETTING ===============
classifier : LSTM
pretrained : True
mode : eval
epochs : 10
batch_size : 64
max_norm : 5.0
embed_trainable : False
device : cuda:0
lr_enc : 0.001
lr_gen : 0.001
num_hidden_rationale : 64
lstm_layer_rationale : 1
lstm_bidirectional_rationale : False
lambda_1 : 2e-05
lambda_2 : 4e-05
num_hidden : 256
lstm_layer : 2
lstm_bidirectional : True
num_classes : 6
kernel_sizes : [2, 3, 4]
p : 0.5
c_out : 32
=============== LOAD EMBEDDINGS ===============
Statistics of Label Mapping:
* Class: {0: 'ABBREVIATION', 1: 'ENTITY', 2: 'DESCRIPTION', 3: 'HUMAN', 4: 'LOCATION', 5: 'NUMERIC'}
+ Total: 6
Embed shape: (4164, 300)
Vocab size: 4164
=============== MODEL TESTING ===============
Testing on 500 data:
+ Overall ACC: 0.788
+ Overall KEEP: 0.722
* ABB PREC: 0.833, ABB REC: 0.556, ABB F1: 0.667
* ENT PREC: 0.725, ENT REC: 0.617, ENT F1: 0.667
* DES PREC: 0.799, DES REC: 0.891, DES F1: 0.842
* HUM PREC: 0.852, HUM REC: 0.800, HUM F1: 0.825
* LOC PREC: 0.705, LOC REC: 0.827, LOC F1: 0.761
* NUM PREC: 0.856, NUM REC: 0.788, NUM F1: 0.820
