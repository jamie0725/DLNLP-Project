=============== HYPERPARAMETER SETTING ===============
mode : train
lr : 0.001
epochs : 10
batch_size : 64
num_classes : 6
max_norm : 5.0
embed_trainable : False
kernel_sizes : [2, 3, 4]
device : cuda:0
p : 0.5
c_out : 32
=============== LOAD EMBEDDINGS ===============
embeddings_shape:(4164, 300)
vocab_size:4164
=============== MODEL TRAINING ===============
iter=10, loss=1.694195, acc=0.2969
iter=20, loss=1.663961, acc=0.3125
iter=30, loss=1.505071, acc=0.4375
iter=40, loss=1.448014, acc=0.5000
iter=50, loss=1.351017, acc=0.5781
iter=60, loss=1.242325, acc=0.5781
iter=70, loss=1.062546, acc=0.6719
iter=80, loss=1.031323, acc=0.5938
iter=90, loss=0.932608, acc=0.7188
iter=100, loss=0.796330, acc=0.7188
iter=110, loss=0.775713, acc=0.7500
iter=120, loss=0.775891, acc=0.6875
iter=130, loss=0.727104, acc=0.7812
iter=140, loss=0.746720, acc=0.7500
iter=150, loss=0.870216, acc=0.7188
iter=160, loss=0.584557, acc=0.8125
iter=170, loss=0.488410, acc=0.8750
iter=180, loss=0.561111, acc=0.8281
iter=190, loss=0.499028, acc=0.8125
iter=200, loss=0.501920, acc=0.7969
iter=210, loss=0.286754, acc=0.8906
iter=220, loss=0.393351, acc=0.8750
iter=230, loss=0.527572, acc=0.8281
iter=240, loss=0.361476, acc=0.8594
iter=250, loss=0.372408, acc=0.9219
iter=260, loss=0.256682, acc=0.9375
iter=270, loss=0.275799, acc=0.9375
iter=280, loss=0.291550, acc=0.9375
iter=290, loss=0.310889, acc=0.8906
iter=300, loss=0.245694, acc=0.9375
iter=310, loss=0.210519, acc=0.9219
iter=320, loss=0.324592, acc=0.8906
iter=330, loss=0.309266, acc=0.9062
iter=340, loss=0.331284, acc=0.9062
iter=350, loss=0.372088, acc=0.8906
iter=360, loss=0.161215, acc=0.9531
iter=370, loss=0.220508, acc=0.9375
iter=380, loss=0.251822, acc=0.9219
iter=390, loss=0.252364, acc=0.9062
iter=400, loss=0.244240, acc=0.9219
iter=410, loss=0.245677, acc=0.9219
iter=420, loss=0.178737, acc=0.9688
iter=430, loss=0.266307, acc=0.9375
iter=440, loss=0.235290, acc=0.9375
iter=450, loss=0.138641, acc=0.9531
iter=460, loss=0.296689, acc=0.8750
iter=470, loss=0.124610, acc=0.9844
iter=480, loss=0.131914, acc=0.9688
iter=490, loss=0.082465, acc=1.0000
iter=500, loss=0.078798, acc=0.9844
iter=510, loss=0.176706, acc=0.9688
iter=520, loss=0.253279, acc=0.9531
iter=530, loss=0.184929, acc=0.9688
iter=540, loss=0.174906, acc=0.9688
iter=550, loss=0.197370, acc=0.9375
iter=560, loss=0.127594, acc=0.9531
iter=570, loss=0.095796, acc=0.9844
iter=580, loss=0.076975, acc=0.9844
iter=590, loss=0.142268, acc=0.9844
iter=600, loss=0.163877, acc=0.9531
iter=610, loss=0.046847, acc=1.0000
iter=620, loss=0.159039, acc=0.9531
iter=630, loss=0.098978, acc=0.9688
iter=640, loss=0.103714, acc=0.9688
iter=650, loss=0.158899, acc=0.9688
iter=660, loss=0.156775, acc=0.9531
iter=670, loss=0.156507, acc=0.9531
iter=680, loss=0.128729, acc=0.9688
iter=690, loss=0.171674, acc=0.9531
iter=700, loss=0.133358, acc=0.9844
iter=710, loss=0.137303, acc=0.9688
iter=720, loss=0.102627, acc=0.9531
iter=730, loss=0.071971, acc=1.0000
iter=740, loss=0.108808, acc=0.9844
iter=750, loss=0.122911, acc=0.9844
iter=760, loss=0.057375, acc=1.0000
iter=770, loss=0.081707, acc=1.0000
iter=780, loss=0.035772, acc=1.0000
iter=790, loss=0.123495, acc=0.9531
iter=800, loss=0.066724, acc=0.9844
iter=810, loss=0.053961, acc=0.9844
iter=820, loss=0.121830, acc=0.9844
iter=830, loss=0.025655, acc=1.0000
iter=840, loss=0.067283, acc=0.9844
iter=850, loss=0.177198, acc=0.9375
iter=860, loss=0.055273, acc=0.9844
iter=870, loss=0.140372, acc=0.9531
iter=880, loss=0.158360, acc=0.9531
iter=890, loss=0.122649, acc=0.9531
iter=900, loss=0.041881, acc=1.0000
iter=910, loss=0.065549, acc=0.9844
iter=920, loss=0.061666, acc=0.9844
iter=930, loss=0.103911, acc=0.9688
iter=940, loss=0.035878, acc=0.9844
iter=950, loss=0.095114, acc=0.9844
iter=960, loss=0.070996, acc=0.9844
iter=970, loss=0.144761, acc=0.9531
iter=980, loss=0.032936, acc=1.0000
iter=990, loss=0.080554, acc=0.9844
iter=1000, loss=0.252708, acc=0.9531
iter=1010, loss=0.030531, acc=1.0000
iter=1020, loss=0.109382, acc=0.9688
iter=1030, loss=0.046347, acc=1.0000
iter=1040, loss=0.028111, acc=1.0000
iter=1050, loss=0.069054, acc=0.9844
iter=1060, loss=0.071208, acc=0.9844
iter=1070, loss=0.070059, acc=0.9688
iter=1080, loss=0.104265, acc=0.9844
iter=1090, loss=0.086059, acc=0.9531
iter=1100, loss=0.026292, acc=1.0000
iter=1110, loss=0.041217, acc=0.9844
iter=1120, loss=0.059609, acc=0.9844
iter=1130, loss=0.089640, acc=0.9531
iter=1140, loss=0.076427, acc=0.9688
iter=1150, loss=0.042683, acc=1.0000
iter=1160, loss=0.042211, acc=1.0000
iter=1170, loss=0.029364, acc=1.0000
iter=1180, loss=0.043789, acc=0.9844
iter=1190, loss=0.022569, acc=1.0000
iter=1200, loss=0.072681, acc=0.9844
iter=1210, loss=0.028636, acc=1.0000
iter=1220, loss=0.113534, acc=0.9844
iter=1230, loss=0.052174, acc=1.0000
iter=1240, loss=0.020008, acc=1.0000
iter=1250, loss=0.016938, acc=0.9844
iter=1260, loss=0.024201, acc=1.0000
iter=1270, loss=0.049900, acc=1.0000
iter=1280, loss=0.020768, acc=1.0000
iter=1290, loss=0.060413, acc=1.0000
iter=1300, loss=0.108448, acc=0.9531
iter=1310, loss=0.033661, acc=1.0000
iter=1320, loss=0.052671, acc=0.9844
iter=1330, loss=0.038151, acc=1.0000
iter=1340, loss=0.067073, acc=0.9688
iter=1350, loss=0.053660, acc=0.9844
iter=1360, loss=0.006886, acc=1.0000
iter=1370, loss=0.006226, acc=1.0000
iter=1380, loss=0.035963, acc=1.0000
iter=1390, loss=0.006910, acc=1.0000
iter=1400, loss=0.035613, acc=1.0000
iter=1410, loss=0.007619, acc=1.0000
iter=1420, loss=0.050525, acc=0.9844
iter=1430, loss=0.039093, acc=1.0000
